{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "necessary-fever",
   "metadata": {},
   "source": [
    "# PART 2: Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "improved-rebecca",
   "metadata": {},
   "source": [
    "**Why data are normalized?**\n",
    "Normalization is common technique in data preparation part in machine learning.\n",
    "The goal of normalization is to change the values of numeric columns in the dataset to a common scale, without distorting differences in the ranges of values.\n",
    "Here different ranges we can notice in `Age`, `Goals90min`, `GoalDifference` etc.  \n",
    "\n",
    "There was an attepmt conducted without normalized data and then data models performance was worse. \n",
    "\n",
    "### Baseline\n",
    "*Always start with a stupid model, no exceptions*\n",
    "\n",
    "Baseline is a model that is both simple to set up and has a reasonable chance of providing decent results. It is usually quick and low cost. \n",
    "\n",
    "Here in this project I use regressor that makes predictions using simple rules.\n",
    "\n",
    "According to the documentation this regressor is useful as a simple baseline to compare with other (real) regressors. \n",
    "I use **mean** strategy to generate predictions.\n",
    "\n",
    "## Random Forest\n",
    "**Random forest** is a supervised machine learning algorithm that grows and combines multiple decision trees to create a “forest.” \n",
    "\n",
    "1. Random Forest grows multiple decision trees which are merged together for a more accurate prediction.\n",
    "2. The logic model is that multiple uncorrelated models (trees) perform much better as a group than they do alone. 3. Each tree gets  a classification or a “vote.” \n",
    "4. The forest chooses the classification with the majority of the “votes.” \n",
    "5. When using Random Forest for regression, the forest picks the average of the outputs of all trees.\n",
    "\n",
    "**Why random forest**\n",
    "- Random forest is much more efficient than a single decision\n",
    "- Resolves the problem of over-fitting and\n",
    "- deals with missing data and usually maintains models accuracy.\n",
    "- Anyways random Forest is less efficient than a neural network. A neural network\n",
    "\n",
    "## Multiple Linear Regression\n",
    "**Linear regression** \n",
    "In this exercise response variable(`ScoreHome` and `ScoreAway`) is affected by more than one predictor variable thus in this case the **Multiple Linear Regression** algorithm is used.\n",
    "\n",
    "Multiple Linear Regression is an extension of Simple Linear since it takes more than one predictor variable to predict the response variable. \n",
    "\n",
    "This aproach is used because I wanted to check how it will perform knowing that this is a regression model, which means the output is a continuous variable. Additionaly regression models are used to predict continuous data such as home prices, temperature, profits etc. Output is not the classification problem since it is not binary or with defined labels. \n",
    "\n",
    "## K-Nearest Neighbors\n",
    "**KNN** algorithm can be used It can be used for both classification and regression problems. Usually used in classification problems. \n",
    "The KNN algorithm uses feature similarity to predict the values of any new data points. This means that the new point is assigned a value based on how closely it resembles the points in the training set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "consolidated-greenhouse",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, ElasticNet\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv('data.csv')\n",
    "# Simply drop teams that were not in specific season\n",
    "data = data.dropna()\n",
    "\n",
    "\n",
    "X = data[['NonPenaltyGoalsHome', 'AgeHome', 'Goals90minHome',\n",
    "          'NonPenaltyGoalsAway', 'AgeAway', 'Goals90minAway', 'RankingPlaceHome',\n",
    "          'GoalForHome', 'GoalAgainstHome', 'GoalDifferenceHome', 'PointsHome',\n",
    "          'TopTeamScorerGoalsHome', 'RankingPlaceAway', 'GoalForAway',\n",
    "          'GoalAgainstAway', 'GoalDifferenceAway', 'PointsAway',\n",
    "          'TopTeamScorerGoalsAway', 'HomeT', 'AwayT', 'Season']]\n",
    "\n",
    "\n",
    "normaliza = MinMaxScaler() \n",
    "X_normal = normaliza.fit_transform(X)\n",
    "X = pd.DataFrame(X_normal)\n",
    "\n",
    "\n",
    "y = data[['ScoreHome', 'ScoreAway']]\n",
    "\n",
    "X_train, X_rem, y_train, y_rem = train_test_split(X, y, train_size=0.6)\n",
    "\n",
    "test_size = 0.5\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(\n",
    "    X_rem, y_rem, test_size=0.5)\n",
    "\n",
    "\n",
    "#BaseLine model\n",
    "dummy_regr = DummyRegressor(strategy=\"mean\")\n",
    "model = LinearRegression()\n",
    "model_KN = KNeighborsRegressor()\n",
    "model_T = DecisionTreeRegressor()\n",
    "model_RF = RandomForestRegressor(n_estimators = 1000, random_state = 42)\n",
    "en = ElasticNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "individual-equilibrium",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model_calc_errors(model,X_train,y_train,X_val,y_val,X_test,y_test):\n",
    "\n",
    "    model.fit(X=X_train, y=y_train)\n",
    "\n",
    "    y_pred_train=model.predict(X_train)\n",
    "    MSE_train=mean_squared_error(y_train, y_pred_train)\n",
    "\n",
    "    y_pred_val=model.predict(X_val)\n",
    "    MSE_val=mean_squared_error(y_val, y_pred_val)\n",
    "  \n",
    "\n",
    "    y_pred_test=model.predict(X_test)\n",
    "    MSE_test=mean_squared_error(y_test, y_pred_test)\n",
    "    RMSE=np.sqrt(MSE_test)\n",
    "    \n",
    "    return [MSE_train, MSE_val, RMSE]\n",
    "\n",
    "models = [model, model_KN, model_RF, model_T,en, dummy_regr]\n",
    "\n",
    "\n",
    "error = pd.DataFrame(columns=['MSE_Train', 'MSE_Valid', 'RMSE_Test'])\n",
    "for model in models:\n",
    "    res = run_model_calc_errors(model, X_train, y_train, X_valid, y_valid, X_test, y_test)\n",
    "    acc_score = model.score(X_test, y_test)\n",
    "    error = error.append({'MSE_Train': res[0],'MSE_Valid': res[1], 'RMSE_Test': res[2]}, ignore_index=True) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "error.rename(index={0:'MultipleLinearRegression',\n",
    "                    1:'KNeighborsRegressor',\n",
    "                    2: 'RandomForestRegressor',\n",
    "                    3: 'DecisionTreeRegressor',\n",
    "                    4: 'ElasticNet',\n",
    "                    5:  'Dummy_regr'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spoken-honor",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(HTML(error.to_html()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fleet-cooperation",
   "metadata": {},
   "source": [
    "A perfect MSE and RMSE value is 0.0, which means that all predictions matched the expected values exactly.\n",
    "\n",
    "This is almost never the case, and if it happens, it suggests that predictive modeling problem is trivial.\n",
    "\n",
    "A good RMSE and RMSE is relative to your specific dataset.\n",
    "\n",
    "Comparing baseline model with other models it is shown that duymmy model is not the worst performing model. Decission tree regressor results note even worse results according to RMSE in valid dataset.\n",
    "\n",
    "I am choosing RandomForestRegressor as the best performing model from all conducted simulations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "direct-finish",
   "metadata": {},
   "source": [
    "## Create CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "romantic-annotation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CSV\n",
    "\n",
    "\n",
    "test = pd.read_csv('2020/test.csv')\n",
    "test2 = pd.DataFrame(columns=[['Home', 'Away']])\n",
    "\n",
    "home = []\n",
    "away = []\n",
    "for ind in test.index:\n",
    "    if (test['Venue'][ind]) == 'Home':\n",
    "        home.append(test['Team'][ind])\n",
    "        away.append(test['Opponent'][ind])\n",
    "    else:\n",
    "        home.append(test['Opponent'][ind])\n",
    "        away.append(test['Team'][ind])\n",
    "\n",
    "test['Home'] = home\n",
    "test['Away'] = away\n",
    "test = test.drop(columns=['Date', 'Team', 'Opponent', 'Venue'])\n",
    "\n",
    "y_pred_Linear_csv_home = []\n",
    "y_pred_Linear_csv_away = []\n",
    "\n",
    "y_pred_KN_csv_home = []\n",
    "y_pred_KN_csv_away = []\n",
    "\n",
    "y_pred_T_csv_home = []\n",
    "y_pred_T_csv_away = []\n",
    "\n",
    "y_pred_RF_csv_home = []\n",
    "y_pred_RF_csv_away = []\n",
    "\n",
    "team_transformed = pd.DataFrame()\n",
    "team_transformed['Home'] = data.Home\n",
    "team_transformed['SquadNO'] = data.HomeT\n",
    "description = team_transformed.drop_duplicates(\n",
    "    ['Home', 'SquadNO'], keep='last')\n",
    "\n",
    "\n",
    "# get X values that will be used in model (need it to predit)\n",
    "get_data = data[['Home', 'Away', 'NonPenaltyGoalsHome', 'AgeHome', 'Goals90minHome',\n",
    "                 'NonPenaltyGoalsAway', 'AgeAway', 'Goals90minAway', 'RankingPlaceHome',\n",
    "                 'GoalForHome', 'GoalAgainstHome', 'GoalDifferenceHome', 'PointsHome',\n",
    "                 'TopTeamScorerGoalsHome', 'RankingPlaceAway', 'GoalForAway',\n",
    "                 'GoalAgainstAway', 'GoalDifferenceAway', 'PointsAway',\n",
    "                 'TopTeamScorerGoalsAway', 'HomeT', 'AwayT', 'Season']]\n",
    "\n",
    "\n",
    "for ind in test.index:\n",
    "    get_h = (test['Home'][ind])\n",
    "    get_a = (test['Away'][ind])\n",
    "    get = get_data[(get_data['Home'] == get_h) & (get_data['Away'] == get_a)]\n",
    "    get = get.drop(columns=['Home', 'Away'])\n",
    "    pred1 = (model.predict(get))\n",
    "    pred2 = (model_KN.predict(get))\n",
    "    pred3 = (model_T.predict(get))\n",
    "    pred4 = (model_RF.predict(get))\n",
    "\n",
    "    \n",
    "    \n",
    "    y_pred_Linear_csv_home.append(round(pred1[0][0]))    \n",
    "    y_pred_Linear_csv_away.append(round(pred1[0][1]))   \n",
    "    \n",
    "    y_pred_KN_csv_home.append(round(pred2[0][0]))   \n",
    "    y_pred_KN_csv_away.append(round(pred2[0][1]))\n",
    "\n",
    "    y_pred_T_csv_home.append(round(pred3[0][0]))    \n",
    "    y_pred_T_csv_away.append(round(pred3[0][1]))    \n",
    "    \n",
    "    y_pred_RF_csv_home.append(round(pred4[0][0]))    \n",
    "    y_pred_RF_csv_away.append(round(pred4[0][1]))\n",
    "\n",
    "test['HomeScore_tree'] = y_pred_T_csv_home\n",
    "test['AwayScore_tree'] = y_pred_T_csv_away\n",
    "\n",
    "test['HomeScore_Linear'] = y_pred_Linear_csv_home\n",
    "test['AwayScore_Linear'] = y_pred_Linear_csv_away\n",
    "\n",
    "test['HomeScore_KN'] = y_pred_KN_csv_home\n",
    "test['AwayScore_KN'] = y_pred_KN_csv_away\n",
    "\n",
    "test['HomeScore_RF'] = y_pred_RF_csv_home\n",
    "test['AwayScore_RF'] = y_pred_RF_csv_away\n",
    "test.to_csv(r'/home/edyta/git/INF161/Project/app/predictions.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
